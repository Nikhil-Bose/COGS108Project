{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('parklandshooting.json')\n",
    "tweets = df['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(t):\n",
    "    t = t.lower()\n",
    "    t = t.strip()\n",
    "    t = t.replace(\"#\",\"\")\n",
    "    t = t.replace(\"@\",\"\")\n",
    "    t = t.replace(\"&\",\"and\")\n",
    "    t = t.replace(\"\\n\",'')\n",
    "    t = t.replace(\"\\'\",'')\n",
    "    t = t.replace('realDonaldTrump','Donald Trump')\n",
    "    \n",
    "    i = t.find('pic.twitter.com')\n",
    "    t = t[0:i]\n",
    "\n",
    "    f = t.find('www.')\n",
    "    j = t.find('.com')\n",
    "    h = t.find('https://')\n",
    "    remove1 = t[h:j]\n",
    "    #t = t.replace(remove1,'')\n",
    "    remove2 = t[f:j]\n",
    "    #t = t.replace(remove2,'')\n",
    "    t = t[0:f]\n",
    "    t = t[0:h]\n",
    "    t = t[0:j]\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = df['text'].apply(clean_tweet)\n",
    "tweets = cleaned_tweets.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=35974, minmax=(-1.0, 1.0), mean=0.015075943518551441, variance=0.072357598695985154, skewness=-0.2663663206284381, kurtosis=2.7908971981913346)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment_analysis(t):\n",
    "    b = TextBlob(t)\n",
    "    return  b.sentiment.polarity\n",
    "\n",
    "sentiments = []\n",
    "for i in range(0,len(tweets)):\n",
    "    sentiments.append(sentiment_analysis(tweets[i]))\n",
    "    \n",
    "sp.stats.describe(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
